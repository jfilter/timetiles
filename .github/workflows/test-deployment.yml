name: Test Production Deployment

on:
  workflow_call:
  workflow_dispatch:
    inputs:
      debug:
        description: 'Enable debug logging'
        required: false
        default: 'false'

jobs:
  test-production-deployment:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Make deploy script executable
        run: chmod +x deploy.sh deployment/deploy.sh

      - name: Run setup
        run: |
          ./deploy.sh setup

          # Verify files were created
          if [ ! -f deployment/.env.production ]; then
            echo "Setup failed - .env.production not created!"
            exit 1
          fi

          # Set test values
          sed -i 's/CHANGE_ME_STRONG_PASSWORD/test_password_123/g' deployment/.env.production
          sed -i 's/your-domain.com/localhost/g' deployment/.env.production
          sed -i 's/admin@${DOMAIN_NAME}/test@localhost/g' deployment/.env.production

          # Show config (without secrets)
          echo "=== Test Configuration ==="
          grep -E "^[^#]" deployment/.env.production | grep -v PASSWORD | grep -v SECRET

      - name: Prepare nginx configuration
        run: |
          echo "Preparing nginx configuration for testing..."

          # Create temporary nginx config directory
          mkdir -p deployment/nginx-test/sites-enabled

          # Copy nginx configs to temp directory
          cp deployment/nginx/nginx.conf deployment/nginx-test/nginx.conf
          cp -r deployment/nginx/sites-enabled/* deployment/nginx-test/sites-enabled/

          # Substitute DOMAIN_NAME in ALL temp configs
          find deployment/nginx-test/sites-enabled -type f -name "*.conf" -exec sed -i 's/${DOMAIN_NAME}/localhost/g' {} \;

          echo "Nginx config prepared with substitutions applied"

          # Create docker-compose override for testing with absolute paths
          cat > deployment/docker-compose.test.yml << EOF
          services:
            nginx:
              volumes:
                - $(pwd)/deployment/nginx-test/nginx.conf:/etc/nginx/nginx.conf:ro
                - $(pwd)/deployment/nginx-test/sites-enabled:/etc/nginx/sites-enabled:ro
                - $(pwd)/deployment/ssl:/etc/letsencrypt:ro
                - certbot-webroot:/var/www/certbot:ro

          volumes:
            certbot-webroot:
          EOF

          echo "Docker compose override created with absolute paths"
          cat deployment/docker-compose.test.yml

      - name: Generate self-signed SSL certificate
        run: |
          echo "Generating self-signed certificate for testing..."

          # Create directory for certificates
          mkdir -p deployment/ssl/live/localhost

          # Generate self-signed certificate
          openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
            -keyout deployment/ssl/live/localhost/privkey.pem \
            -out deployment/ssl/live/localhost/fullchain.pem \
            -subj "/C=US/ST=Test/L=Test/O=Test/CN=localhost"

          echo "SSL certificates generated"

      - name: Build Docker image
        run: |
          ./deploy.sh build

          # Check image size
          IMAGE_SIZE=$(docker images --format "{{.Size}}" timetiles-web:latest)
          echo "Docker image size: $IMAGE_SIZE"

      - name: Start services
        run: |
          ./deploy.sh up

      - name: Wait for services to be healthy
        run: |
          echo "Waiting for services to be ready..."
          sleep 10

          ./deploy.sh status

          echo "Waiting for web app via nginx (testing production-like setup)..."
          echo "Note: Migrations run automatically via prodMigrations on startup"
          max_attempts=30
          attempt=0
          while [ $attempt -lt $max_attempts ]; do
            if curl -f --max-time 5 http://localhost:80/api/health 2>/dev/null; then
              echo "Health check passed via nginx!"
              break
            fi
            echo "Waiting for application... (attempt $((attempt+1))/$max_attempts)"
            sleep 2
            attempt=$((attempt+1))
          done

          if [ $attempt -eq $max_attempts ]; then
            echo "Health check failed after $max_attempts attempts"
            echo "Checking nginx and web container logs:"
            cd deployment
            docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production logs --tail=50
            exit 1
          fi

      - name: Test nginx proxy (HTTP and HTTPS)
        run: |
          echo "Testing nginx is proxying correctly..."

          # Test HTTPS redirect from HTTP (HTTP redirects to HTTPS by design)
          REDIRECT_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:80/api/health)
          if [ "$REDIRECT_CODE" != "301" ]; then
            echo "Expected 301 redirect from HTTP, got $REDIRECT_CODE"
            exit 1
          fi
          echo "HTTP to HTTPS redirect working correctly"

          # Test health endpoint through nginx HTTPS (ignore self-signed cert)
          curl -f -k -v https://localhost:443/api/health || exit 1

          # Test static files over HTTPS
          curl -f -k -I https://localhost:443/_next/static/ || echo "Note: Static files may not exist in minimal test"
          
          # Test Let's Encrypt challenge path (certbot writes, nginx serves over HTTP)
          cd deployment
          DC_CMD="docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production"
          $DC_CMD exec -T certbot mkdir -p /var/www/certbot/.well-known/acme-challenge
          $DC_CMD exec -T certbot sh -c 'echo "test" > /var/www/certbot/.well-known/acme-challenge/test.txt'
          cd ..
          curl -f http://localhost:80/.well-known/acme-challenge/test.txt || exit 1
          
      - name: Test application endpoints (HTTPS)
        run: |
          echo "Testing application endpoints over HTTPS..."

          # Test API health over HTTPS
          echo "Testing /api/health..."
          HEALTH_RESPONSE=$(curl -k -s --max-time 10 https://localhost:443/api/health)
          echo "Health check response: $HEALTH_RESPONSE"

          # Test explore page loads over HTTPS
          echo "Testing /explore page..."
          if ! curl -f -k -s --max-time 10 https://localhost:443/explore | grep -q "<html"; then
            echo "ERROR: Explore page did not return HTML"
            curl -k -s --max-time 10 https://localhost:443/explore | head -20
            exit 1
          fi
          echo "Explore page OK"

          # Test security headers are present
          echo "Checking security headers..."
          curl -k -I --max-time 10 https://localhost:443/explore | grep -i "strict-transport-security" || echo "Warning: HSTS header missing"
          curl -k -I --max-time 10 https://localhost:443/explore | grep -i "x-frame-options" || echo "Warning: X-Frame-Options missing"
          curl -k -I --max-time 10 https://localhost:443/explore | grep -i "x-content-type-options" || echo "Warning: X-Content-Type-Options missing"
          
      - name: Test database connectivity
        run: |
          echo "Testing database operations..."
          cd deployment
          DC_CMD="docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production"

          # Check PostGIS is installed (use PGPASSWORD with TCP/IP connection)
          $DC_CMD exec -T postgres bash -c 'PGPASSWORD=$POSTGRES_PASSWORD psql -h localhost -U timetiles_user -d timetiles -c "SELECT PostGIS_Version();"'

          # Check Payload schema exists
          $DC_CMD exec -T postgres bash -c 'PGPASSWORD=$POSTGRES_PASSWORD psql -h localhost -U timetiles_user -d timetiles -c "\dn payload"'
          cd ..

      - name: Test container restart
        run: |
          ./deploy.sh restart

          # Wait for it to come back (check via nginx)
          sleep 10
          timeout 60 bash -c 'until curl -f --max-time 5 http://localhost:80/api/health 2>/dev/null; do sleep 2; done'

          echo "Container restart successful!"
          
      - name: Check resource usage
        run: |
          echo "=== Container Resource Usage ==="
          docker stats --no-stream
          
          echo "=== Docker Images ==="
          docker images | grep timetiles
          
      - name: Test backup and restore functionality
        run: |
          cd deployment
          DC_CMD="docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production"

          # Helper to run SQL using deploy.sh pattern (POSTGRES_PASS from container env)
          run_sql() {
            $DC_CMD exec -T postgres bash -c "PGPASSWORD=\$POSTGRES_PASS psql -h localhost -U \$POSTGRES_USER -d \$POSTGRES_DBNAME -c \"$1\""
          }

          run_sql_quiet() {
            $DC_CMD exec -T postgres bash -c "PGPASSWORD=\$POSTGRES_PASS psql -h localhost -U \$POSTGRES_USER -d \$POSTGRES_DBNAME -t -c \"$1\""
          }

          echo "=== Phase 1: Create test data (database + uploads) ==="

          # Create test user with multiple fields
          run_sql "INSERT INTO payload.users (email, role, created_at, updated_at) VALUES ('backup-test@example.com', 'user', '2024-01-15 10:30:00', '2024-01-15 10:30:00');"

          # Create test dataset record
          run_sql "INSERT INTO payload.datasets (name, slug, description, created_at, updated_at) VALUES ('Backup Test Dataset', 'backup-test-dataset', 'Dataset for backup testing', NOW(), NOW());"

          # Create test files in uploads volume (both media and import-files subdirs)
          UPLOAD_VOL=$(docker volume ls -q | grep -E 'timetiles.*uploads' | head -1)
          echo "Upload volume: $UPLOAD_VOL"

          docker run --rm -v "$UPLOAD_VOL:/uploads" alpine sh -c "
            mkdir -p /uploads/media /uploads/import-files
            echo 'test-media-content-12345' > /uploads/media/test-image.txt
            echo 'test-import-content-67890' > /uploads/import-files/test-import.csv
          "

          # Verify test files exist
          echo "Verifying test files were created..."
          docker run --rm -v "$UPLOAD_VOL:/uploads" alpine ls -la /uploads/media/ /uploads/import-files/

          echo "=== Phase 2: Test database-only backup ==="
          ./deploy.sh backup db

          if ! ls backups/db-*.sql.gz > /dev/null 2>&1; then
            echo "ERROR: Database backup failed - no backup file found"
            exit 1
          fi
          echo "Database backup created successfully"

          echo "=== Phase 3: Test full backup (database + uploads) ==="
          ./deploy.sh backup full

          if ! ls backups/uploads-*.tar.gz > /dev/null 2>&1; then
            echo "ERROR: Full backup failed - no uploads backup found"
            exit 1
          fi
          echo "Full backup created successfully"

          # List all backups
          ./deploy.sh backup list

          # Get latest backup filenames
          LATEST_DB_BACKUP=$(find backups -name 'db-*.sql.gz' -type f -printf '%T@ %p\n' | sort -rn | head -1 | cut -d' ' -f2 | xargs basename)
          LATEST_UPLOADS_BACKUP=$(find backups -name 'uploads-*.tar.gz' -type f -printf '%T@ %p\n' | sort -rn | head -1 | cut -d' ' -f2 | xargs basename)
          echo "Latest DB backup: $LATEST_DB_BACKUP"
          echo "Latest uploads backup: $LATEST_UPLOADS_BACKUP"

          echo "=== Phase 4: Delete all test data ==="

          # Delete database records
          run_sql "DELETE FROM payload.users WHERE email = 'backup-test@example.com';"
          run_sql "DELETE FROM payload.datasets WHERE slug = 'backup-test-dataset';"

          # Delete uploaded files
          docker run --rm -v "$UPLOAD_VOL:/uploads" alpine sh -c "
            rm -f /uploads/media/test-image.txt /uploads/import-files/test-import.csv
          "

          # Verify database data is gone
          USER_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.users WHERE email = 'backup-test@example.com';" | tr -d ' ')
          DATASET_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.datasets WHERE slug = 'backup-test-dataset';" | tr -d ' ')

          if [ "$USER_COUNT" != "0" ] || [ "$DATASET_COUNT" != "0" ]; then
            echo "ERROR: Failed to delete test database records"
            exit 1
          fi

          # Verify files are gone
          if docker run --rm -v "$UPLOAD_VOL:/uploads" alpine test -f /uploads/media/test-image.txt; then
            echo "ERROR: Failed to delete test media file"
            exit 1
          fi
          if docker run --rm -v "$UPLOAD_VOL:/uploads" alpine test -f /uploads/import-files/test-import.csv; then
            echo "ERROR: Failed to delete test import file"
            exit 1
          fi
          echo "All test data deleted successfully"

          echo "=== Phase 5a: Test database-only restore ==="
          echo "yes" | ./deploy.sh restore "$LATEST_DB_BACKUP"

          # Verify database records restored
          USER_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.users WHERE email = 'backup-test@example.com';" | tr -d ' ')
          if [ "$USER_COUNT" != "1" ]; then
            echo "ERROR: User record not restored after db-only restore (count: $USER_COUNT)"
            exit 1
          fi
          echo "Database-only restore: user record restored"

          # Verify uploads were NOT restored (files should still be missing)
          if docker run --rm -v "$UPLOAD_VOL:/uploads" alpine test -f /uploads/media/test-image.txt 2>/dev/null; then
            echo "ERROR: Media file should not exist after db-only restore"
            exit 1
          fi
          echo "Database-only restore: uploads correctly unchanged"

          # Delete db records again for full restore test
          run_sql "DELETE FROM payload.users WHERE email = 'backup-test@example.com';"
          run_sql "DELETE FROM payload.datasets WHERE slug = 'backup-test-dataset';"

          echo "=== Phase 5b: Test full restore (database + uploads) ==="
          echo "yes" | ./deploy.sh restore "$LATEST_DB_BACKUP" "$LATEST_UPLOADS_BACKUP"

          echo "=== Phase 6: Verify fully restored data ==="

          # Verify database records restored
          USER_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.users WHERE email = 'backup-test@example.com';" | tr -d ' ')
          if [ "$USER_COUNT" != "1" ]; then
            echo "ERROR: User record not restored (count: $USER_COUNT)"
            exit 1
          fi

          # Verify user fields restored correctly
          USER_ROLE=$(run_sql_quiet "SELECT role FROM payload.users WHERE email = 'backup-test@example.com';" | tr -d ' ')
          if [ "$USER_ROLE" != "user" ]; then
            echo "ERROR: User role not restored correctly (got: $USER_ROLE)"
            exit 1
          fi
          echo "User record restored with correct fields"

          DATASET_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.datasets WHERE slug = 'backup-test-dataset';" | tr -d ' ')
          if [ "$DATASET_COUNT" != "1" ]; then
            echo "ERROR: Dataset record not restored (count: $DATASET_COUNT)"
            exit 1
          fi

          # Verify dataset fields
          DATASET_NAME=$(run_sql_quiet "SELECT name FROM payload.datasets WHERE slug = 'backup-test-dataset';" | xargs)
          if [ "$DATASET_NAME" != "Backup Test Dataset" ]; then
            echo "ERROR: Dataset name not restored correctly (got: $DATASET_NAME)"
            exit 1
          fi
          echo "Dataset record restored with correct fields"

          # Verify uploaded files restored
          MEDIA_CONTENT=$(docker run --rm -v "$UPLOAD_VOL:/uploads" alpine cat /uploads/media/test-image.txt 2>/dev/null || echo "")
          if [ "$MEDIA_CONTENT" != "test-media-content-12345" ]; then
            echo "ERROR: Media file not restored correctly (got: $MEDIA_CONTENT)"
            exit 1
          fi
          echo "Media file restored correctly"

          IMPORT_CONTENT=$(docker run --rm -v "$UPLOAD_VOL:/uploads" alpine cat /uploads/import-files/test-import.csv 2>/dev/null || echo "")
          if [ "$IMPORT_CONTENT" != "test-import-content-67890" ]; then
            echo "ERROR: Import file not restored correctly (got: $IMPORT_CONTENT)"
            exit 1
          fi
          echo "Import file restored correctly"

          echo "=== Phase 7: Test backup verification ==="
          ./deploy.sh backup verify

          # Verify it shows valid backups with table counts
          VERIFY_OUTPUT=$(./deploy.sh backup verify 2>&1)
          if ! echo "$VERIFY_OUTPUT" | grep -q "valid"; then
            echo "ERROR: Verify command didn't report valid backups"
            echo "$VERIFY_OUTPUT"
            exit 1
          fi
          echo "Backup verification passed"

          echo "=== Phase 8: Test corrupted file detection ==="

          # Create corrupted test files
          head -c 100 backups/db-*.sql.gz 2>/dev/null | head -c 100 > backups/db-test-corrupted.sql.gz
          echo 'not a dump' | gzip > backups/db-test-invalid.sql.gz

          # Run verify and check it detects corruption
          VERIFY_OUTPUT=$(./deploy.sh backup verify 2>&1)
          if ! echo "$VERIFY_OUTPUT" | grep -q "CORRUPTED"; then
            echo "ERROR: Failed to detect corrupted gzip file"
            echo "$VERIFY_OUTPUT"
            exit 1
          fi
          if ! echo "$VERIFY_OUTPUT" | grep -q "INVALID"; then
            echo "ERROR: Failed to detect invalid pg_dump content"
            echo "$VERIFY_OUTPUT"
            exit 1
          fi
          echo "Corrupted file detection working correctly"

          # Clean up test files
          rm -f backups/db-test-*.sql.gz

          echo "=== Phase 9: Test backup clean (time-based deletion) ==="

          # Create old backup files with 32-day old timestamps
          echo 'old' | gzip > backups/db-old-test.sql.gz
          touch -d '32 days ago' backups/db-old-test.sql.gz
          echo 'old' | gzip > backups/uploads-old-test.tar.gz
          touch -d '32 days ago' backups/uploads-old-test.tar.gz

          # Count before clean
          OLD_COUNT_BEFORE=$(ls -1 backups/*-old-test.* 2>/dev/null | wc -l)
          echo "Old test files before clean: $OLD_COUNT_BEFORE"

          # Run clean with default 30 days
          ./deploy.sh backup clean

          # Verify old files were deleted
          OLD_COUNT_AFTER=$(ls -1 backups/*-old-test.* 2>/dev/null | wc -l)
          if [ "$OLD_COUNT_AFTER" -ne 0 ]; then
            echo "ERROR: Clean didn't delete old files (expected 0, got $OLD_COUNT_AFTER)"
            exit 1
          fi
          echo "Backup clean deleted old files correctly"

          echo "=== Phase 10: Test backup pruning ==="

          # Create extra backups to have enough to prune
          ./deploy.sh backup db
          ./deploy.sh backup db

          # Count before prune
          DB_COUNT_BEFORE=$(ls -1 backups/db-*.sql.gz 2>/dev/null | wc -l)
          echo "Database backups before prune: $DB_COUNT_BEFORE"

          # Prune to keep only 2
          ./deploy.sh backup prune 2

          # Count after prune
          DB_COUNT_AFTER=$(ls -1 backups/db-*.sql.gz 2>/dev/null | wc -l)
          echo "Database backups after prune: $DB_COUNT_AFTER"

          if [ "$DB_COUNT_AFTER" -gt 2 ]; then
            echo "ERROR: Prune didn't reduce backup count (expected <=2, got $DB_COUNT_AFTER)"
            exit 1
          fi
          echo "Backup pruning works correctly"

          echo "=== All backup and restore tests passed! ==="

          # Cleanup
          echo "Cleaning up test data..."
          ./deploy.sh backup clean
          run_sql "DELETE FROM payload.users WHERE email = 'backup-test@example.com';"
          run_sql "DELETE FROM payload.datasets WHERE slug = 'backup-test-dataset';"
          docker run --rm -v "$UPLOAD_VOL:/uploads" alpine sh -c \
            "rm -f /uploads/media/test-image.txt /uploads/import-files/test-import.csv"

          cd ..

      - name: Collect logs on failure
        if: failure()
        run: |
          cd deployment
          docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production logs --tail=200

      - name: Cleanup
        if: always()
        run: |
          ./deploy.sh down || true
          docker system prune -f
