name: Test Production Deployment

on:
  workflow_call:
  workflow_dispatch:
    inputs:
      debug:
        description: 'Enable debug logging'
        required: false
        default: 'false'

jobs:
  test-production-deployment:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Make deploy script executable
        run: chmod +x timetiles deployment/timetiles

      - name: Run setup
        run: |
          ./timetiles setup

          # Verify files were created
          if [ ! -f deployment/.env.production ]; then
            echo "Setup failed - .env.production not created!"
            exit 1
          fi

          # Set test values
          sed -i 's/CHANGE_ME_STRONG_PASSWORD/test_password_123/g' deployment/.env.production
          sed -i 's/your-domain.com/localhost/g' deployment/.env.production
          sed -i 's/admin@${DOMAIN_NAME}/test@localhost/g' deployment/.env.production

          # Show config (without secrets)
          echo "=== Test Configuration ==="
          grep -E "^[^#]" deployment/.env.production | grep -v PASSWORD | grep -v SECRET

      - name: Prepare nginx configuration
        run: |
          echo "Preparing nginx configuration for testing..."

          # Create temporary nginx config directory
          mkdir -p deployment/nginx-test/sites-enabled

          # Copy nginx configs to temp directory
          cp deployment/nginx/nginx.conf deployment/nginx-test/nginx.conf
          cp -r deployment/nginx/sites-enabled/* deployment/nginx-test/sites-enabled/

          # Substitute DOMAIN_NAME in ALL temp configs
          find deployment/nginx-test/sites-enabled -type f -name "*.conf" -exec sed -i 's/${DOMAIN_NAME}/localhost/g' {} \;

          echo "Nginx config prepared with substitutions applied"

          # Create docker-compose override for testing with absolute paths
          cat > deployment/docker-compose.test.yml << EOF
          services:
            nginx:
              volumes:
                - $(pwd)/deployment/nginx-test/nginx.conf:/etc/nginx/nginx.conf:ro
                - $(pwd)/deployment/nginx-test/sites-enabled:/etc/nginx/sites-enabled:ro
                - $(pwd)/deployment/ssl:/etc/letsencrypt:ro
                - certbot-webroot:/var/www/certbot:ro

          volumes:
            certbot-webroot:
          EOF

          echo "Docker compose override created with absolute paths"
          cat deployment/docker-compose.test.yml

      - name: Generate self-signed SSL certificate
        run: |
          echo "Generating self-signed certificate for testing..."

          # Create directory for certificates
          mkdir -p deployment/ssl/live/localhost

          # Generate self-signed certificate
          openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
            -keyout deployment/ssl/live/localhost/privkey.pem \
            -out deployment/ssl/live/localhost/fullchain.pem \
            -subj "/C=US/ST=Test/L=Test/O=Test/CN=localhost"

          echo "SSL certificates generated"

      - name: Build Docker image
        run: |
          ./timetiles build

          # Check image size
          IMAGE_SIZE=$(docker images --format "{{.Size}}" timetiles-web:latest)
          echo "Docker image size: $IMAGE_SIZE"

      - name: Start services
        run: |
          ./timetiles up

      - name: Wait for services to be healthy
        run: |
          echo "Waiting for services to be ready..."
          sleep 10

          ./timetiles status

          echo "Waiting for web app via nginx (testing production-like setup)..."
          echo "Note: Migrations run automatically via prodMigrations on startup"
          max_attempts=30
          attempt=0
          while [ $attempt -lt $max_attempts ]; do
            if curl -f --max-time 5 http://localhost:80/api/health 2>/dev/null; then
              echo "Health check passed via nginx!"
              break
            fi
            echo "Waiting for application... (attempt $((attempt+1))/$max_attempts)"
            sleep 2
            attempt=$((attempt+1))
          done

          if [ $attempt -eq $max_attempts ]; then
            echo "Health check failed after $max_attempts attempts"
            echo "Checking nginx and web container logs:"
            cd deployment
            docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production logs --tail=50
            exit 1
          fi

      - name: Test nginx proxy (HTTP and HTTPS)
        run: |
          echo "Testing nginx is proxying correctly..."

          # Test HTTPS redirect from HTTP (HTTP redirects to HTTPS by design)
          REDIRECT_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:80/api/health)
          if [ "$REDIRECT_CODE" != "301" ]; then
            echo "Expected 301 redirect from HTTP, got $REDIRECT_CODE"
            exit 1
          fi
          echo "HTTP to HTTPS redirect working correctly"

          # Test health endpoint through nginx HTTPS (ignore self-signed cert)
          curl -f -k -v https://localhost:443/api/health || exit 1

          # Test static files over HTTPS
          curl -f -k -I https://localhost:443/_next/static/ || echo "Note: Static files may not exist in minimal test"
          
          # Test Let's Encrypt challenge path (certbot writes, nginx serves over HTTP)
          cd deployment
          DC_CMD="docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production"
          $DC_CMD exec -T certbot mkdir -p /var/www/certbot/.well-known/acme-challenge
          $DC_CMD exec -T certbot sh -c 'echo "test" > /var/www/certbot/.well-known/acme-challenge/test.txt'
          cd ..
          curl -f http://localhost:80/.well-known/acme-challenge/test.txt || exit 1
          
      - name: Test application endpoints (HTTPS)
        run: |
          echo "Testing application endpoints over HTTPS..."

          # Test API health over HTTPS
          echo "Testing /api/health..."
          HEALTH_RESPONSE=$(curl -k -s --max-time 10 https://localhost:443/api/health)
          echo "Health check response: $HEALTH_RESPONSE"

          # Test explore page loads over HTTPS
          echo "Testing /explore page..."
          if ! curl -f -k -s --max-time 10 https://localhost:443/explore | grep -q "<html"; then
            echo "ERROR: Explore page did not return HTML"
            curl -k -s --max-time 10 https://localhost:443/explore | head -20
            exit 1
          fi
          echo "Explore page OK"

          # Test security headers are present
          echo "Checking security headers..."
          curl -k -I --max-time 10 https://localhost:443/explore | grep -i "strict-transport-security" || echo "Warning: HSTS header missing"
          curl -k -I --max-time 10 https://localhost:443/explore | grep -i "x-frame-options" || echo "Warning: X-Frame-Options missing"
          curl -k -I --max-time 10 https://localhost:443/explore | grep -i "x-content-type-options" || echo "Warning: X-Content-Type-Options missing"
          
      - name: Test database connectivity
        run: |
          echo "Testing database operations..."
          cd deployment
          DC_CMD="docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production"

          # Check PostGIS is installed (use PGPASSWORD with TCP/IP connection)
          $DC_CMD exec -T postgres bash -c 'PGPASSWORD=$POSTGRES_PASSWORD psql -h localhost -U timetiles_user -d timetiles -c "SELECT PostGIS_Version();"'

          # Check Payload schema exists
          $DC_CMD exec -T postgres bash -c 'PGPASSWORD=$POSTGRES_PASSWORD psql -h localhost -U timetiles_user -d timetiles -c "\dn payload"'
          cd ..

      - name: Test container restart
        run: |
          ./timetiles restart

          # Wait for it to come back (check via nginx)
          sleep 10
          timeout 60 bash -c 'until curl -f --max-time 5 http://localhost:80/api/health 2>/dev/null; do sleep 2; done'

          echo "Container restart successful!"
          
      - name: Check resource usage
        run: |
          echo "=== Container Resource Usage ==="
          docker stats --no-stream
          
          echo "=== Docker Images ==="
          docker images | grep timetiles
          
      - name: Test backup and restore functionality
        run: |
          cd deployment
          DC_CMD="docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production"

          # Load restic config
          source .env.production
          export RESTIC_PASSWORD

          # Helper to run SQL using timetiles pattern (POSTGRES_PASS from container env)
          run_sql() {
            $DC_CMD exec -T postgres bash -c "PGPASSWORD=\$POSTGRES_PASS psql -h localhost -U \$POSTGRES_USER -d \$POSTGRES_DBNAME -c \"$1\""
          }

          run_sql_quiet() {
            $DC_CMD exec -T postgres bash -c "PGPASSWORD=\$POSTGRES_PASS psql -h localhost -U \$POSTGRES_USER -d \$POSTGRES_DBNAME -t -c \"$1\""
          }

          echo "=== Phase 1: Create test data (database + uploads) ==="

          # Create test user with multiple fields
          run_sql "INSERT INTO payload.users (email, role, created_at, updated_at) VALUES ('backup-test@example.com', 'user', '2024-01-15 10:30:00', '2024-01-15 10:30:00');"

          # Create test dataset record
          run_sql "INSERT INTO payload.datasets (name, slug, description, created_at, updated_at) VALUES ('Backup Test Dataset', 'backup-test-dataset', 'Dataset for backup testing', NOW(), NOW());"

          # Create test files in uploads volume (both media and import-files subdirs)
          UPLOAD_VOL=$(docker volume ls -q | grep -E 'timetiles.*uploads' | head -1)
          echo "Upload volume: $UPLOAD_VOL"

          docker run --rm -v "$UPLOAD_VOL:/uploads" alpine sh -c "
            mkdir -p /uploads/media /uploads/import-files
            echo 'test-media-content-12345' > /uploads/media/test-image.txt
            echo 'test-import-content-67890' > /uploads/import-files/test-import.csv
          "

          # Verify test files exist
          echo "Verifying test files were created..."
          docker run --rm -v "$UPLOAD_VOL:/uploads" alpine ls -la /uploads/media/ /uploads/import-files/

          echo "=== Phase 2: Test database backup (restic) ==="
          ./timetiles backup db

          # Verify snapshot was created
          SNAPSHOT_COUNT=$(restic -r "$RESTIC_REPOSITORY" snapshots --json 2>/dev/null | jq length)
          echo "Snapshot count after db backup: $SNAPSHOT_COUNT"
          if [ "$SNAPSHOT_COUNT" -lt 1 ]; then
            echo "ERROR: Database backup failed - no snapshot found"
            exit 1
          fi
          echo "Database backup created successfully"

          echo "=== Phase 3: Test uploads backup (restic) ==="
          ./timetiles backup uploads

          # Verify we now have 2 snapshots
          SNAPSHOT_COUNT=$(restic -r "$RESTIC_REPOSITORY" snapshots --json 2>/dev/null | jq length)
          echo "Snapshot count after uploads backup: $SNAPSHOT_COUNT"
          if [ "$SNAPSHOT_COUNT" -lt 2 ]; then
            echo "ERROR: Uploads backup failed - expected at least 2 snapshots"
            exit 1
          fi
          echo "Uploads backup created successfully"

          # List all snapshots
          ./timetiles backup list

          # Get the db snapshot ID (latest with db tag)
          DB_SNAPSHOT=$(restic -r "$RESTIC_REPOSITORY" snapshots --json --tag db --latest 1 2>/dev/null | jq -r '.[0].short_id')
          UPLOADS_SNAPSHOT=$(restic -r "$RESTIC_REPOSITORY" snapshots --json --tag uploads --latest 1 2>/dev/null | jq -r '.[0].short_id')
          echo "Latest DB snapshot: $DB_SNAPSHOT"
          echo "Latest uploads snapshot: $UPLOADS_SNAPSHOT"

          echo "=== Phase 4: Delete all test data ==="

          # Delete database records
          run_sql "DELETE FROM payload.users WHERE email = 'backup-test@example.com';"
          run_sql "DELETE FROM payload.datasets WHERE slug = 'backup-test-dataset';"

          # Delete uploaded files
          docker run --rm -v "$UPLOAD_VOL:/uploads" alpine sh -c "
            rm -f /uploads/media/test-image.txt /uploads/import-files/test-import.csv
          "

          # Verify database data is gone
          USER_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.users WHERE email = 'backup-test@example.com';" | tr -d ' ')
          DATASET_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.datasets WHERE slug = 'backup-test-dataset';" | tr -d ' ')

          if [ "$USER_COUNT" != "0" ] || [ "$DATASET_COUNT" != "0" ]; then
            echo "ERROR: Failed to delete test database records"
            exit 1
          fi

          # Verify files are gone
          if docker run --rm -v "$UPLOAD_VOL:/uploads" alpine test -f /uploads/media/test-image.txt; then
            echo "ERROR: Failed to delete test media file"
            exit 1
          fi
          if docker run --rm -v "$UPLOAD_VOL:/uploads" alpine test -f /uploads/import-files/test-import.csv; then
            echo "ERROR: Failed to delete test import file"
            exit 1
          fi
          echo "All test data deleted successfully"

          echo "=== Phase 5: Test database restore from snapshot ==="
          echo "y" | ./timetiles restore "$DB_SNAPSHOT"

          # Verify database records restored
          USER_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.users WHERE email = 'backup-test@example.com';" | tr -d ' ')
          if [ "$USER_COUNT" != "1" ]; then
            echo "ERROR: User record not restored (count: $USER_COUNT)"
            exit 1
          fi
          echo "Database restore: user record restored"

          # Verify user fields restored correctly
          USER_ROLE=$(run_sql_quiet "SELECT role FROM payload.users WHERE email = 'backup-test@example.com';" | tr -d ' ')
          if [ "$USER_ROLE" != "user" ]; then
            echo "ERROR: User role not restored correctly (got: $USER_ROLE)"
            exit 1
          fi
          echo "User record restored with correct fields"

          DATASET_COUNT=$(run_sql_quiet "SELECT COUNT(*) FROM payload.datasets WHERE slug = 'backup-test-dataset';" | tr -d ' ')
          if [ "$DATASET_COUNT" != "1" ]; then
            echo "ERROR: Dataset record not restored (count: $DATASET_COUNT)"
            exit 1
          fi

          # Verify dataset fields
          DATASET_NAME=$(run_sql_quiet "SELECT name FROM payload.datasets WHERE slug = 'backup-test-dataset';" | xargs)
          if [ "$DATASET_NAME" != "Backup Test Dataset" ]; then
            echo "ERROR: Dataset name not restored correctly (got: $DATASET_NAME)"
            exit 1
          fi
          echo "Dataset record restored with correct fields"

          echo "=== Phase 6: Test uploads restore from snapshot ==="
          echo "y" | ./timetiles restore "$UPLOADS_SNAPSHOT"

          # Verify uploaded files restored
          MEDIA_CONTENT=$(docker run --rm -v "$UPLOAD_VOL:/uploads" alpine cat /uploads/media/test-image.txt 2>/dev/null || echo "")
          if [ "$MEDIA_CONTENT" != "test-media-content-12345" ]; then
            echo "ERROR: Media file not restored correctly (got: $MEDIA_CONTENT)"
            exit 1
          fi
          echo "Media file restored correctly"

          IMPORT_CONTENT=$(docker run --rm -v "$UPLOAD_VOL:/uploads" alpine cat /uploads/import-files/test-import.csv 2>/dev/null || echo "")
          if [ "$IMPORT_CONTENT" != "test-import-content-67890" ]; then
            echo "ERROR: Import file not restored correctly (got: $IMPORT_CONTENT)"
            exit 1
          fi
          echo "Import file restored correctly"

          echo "=== Phase 7: Test backup verification ==="
          ./timetiles backup verify

          echo "=== Phase 8: Test backup pruning ==="

          # Create extra backups
          ./timetiles backup db
          ./timetiles backup db

          # Count before prune
          SNAPSHOT_COUNT_BEFORE=$(restic -r "$RESTIC_REPOSITORY" snapshots --json 2>/dev/null | jq length)
          echo "Snapshots before prune: $SNAPSHOT_COUNT_BEFORE"

          # Prune (uses retention policy from config)
          ./timetiles backup prune

          # Count after prune
          SNAPSHOT_COUNT_AFTER=$(restic -r "$RESTIC_REPOSITORY" snapshots --json 2>/dev/null | jq length)
          echo "Snapshots after prune: $SNAPSHOT_COUNT_AFTER"
          echo "Backup pruning completed"

          echo "=== All backup and restore tests passed! ==="

          # Cleanup
          echo "Cleaning up test data..."
          run_sql "DELETE FROM payload.users WHERE email = 'backup-test@example.com';"
          run_sql "DELETE FROM payload.datasets WHERE slug = 'backup-test-dataset';"
          docker run --rm -v "$UPLOAD_VOL:/uploads" alpine sh -c \
            "rm -f /uploads/media/test-image.txt /uploads/import-files/test-import.csv"

          cd ..

      - name: Collect logs on failure
        if: failure()
        run: |
          cd deployment
          docker compose -f docker-compose.prod.yml -f docker-compose.test.yml --env-file .env.production logs --tail=200

      - name: Cleanup
        if: always()
        run: |
          ./timetiles down || true
          docker system prune -f
