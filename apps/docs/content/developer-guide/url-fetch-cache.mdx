# URL Fetch Cache System

The URL fetch cache system provides intelligent caching for scheduled URL imports, reducing redundant network requests, respecting API rate limits, and improving import performance.

## Overview

### What It Does

The URL fetch cache automatically stores responses from external APIs and data sources when fetching data for scheduled imports. It implements standard HTTP caching mechanisms including:

- **Conditional requests** with `ETag` and `Last-Modified` headers
- **Cache revalidation** using 304 Not Modified responses
- **Server directives** via `Cache-Control` headers
- **Automatic TTL management** based on response headers

### Why Use It

**Benefits:**

1. **Reduces API consumption** - Avoids re-downloading unchanged data
2. **Respects rate limits** - Fewer requests to external APIs
3. **Faster imports** - Cached responses return immediately
4. **Quota savings** - Cached hits don't count against geocoding or API quotas
5. **Bandwidth efficiency** - 304 responses transfer minimal data

**When It's Used:**

The cache is automatically integrated with:
- Scheduled imports that fetch data from URLs
- Manual import triggers (configurable)
- Webhook-triggered imports (configurable)

The cache operates transparently through the `url-fetch-job` handler - no programmatic integration required.

### How Caching Works

**Cache Hit Flow:**
```
Request → Check cache → Found & valid → Return cached response ✓
```

**Cache Miss Flow:**
```
Request → Check cache → Not found → Fetch from URL → Store → Return response
```

**Revalidation Flow:**
```
Request → Check cache → Found but stale → Send conditional request with ETag
→ 304 Not Modified → Update cache metadata → Return cached response ✓
→ 200 OK with new data → Update cache → Return new response
```

## Configuration

### Quick Reference: Which Variables to Use?

| What you want to configure | Use these variables | NOT these |
|---------------------------|---------------------|-----------|
| **URL fetch cache for scheduled imports** | `URL_FETCH_CACHE_*` | ~~`CACHE_*`~~ |
| **Other caching in TimeTiles** | `CACHE_*` | ~~`URL_FETCH_CACHE_*`~~ |

⚠️ **Important:** Don't mix them up! URL fetch cache and generic cache are completely separate systems.

### Environment Variables

#### URL Fetch Cache Settings

```bash
# Cache directory (filesystem backend)
URL_FETCH_CACHE_DIR=/tmp/url-fetch-cache

# Maximum cache size in bytes (default: 100MB)
URL_FETCH_CACHE_MAX_SIZE=104857600

# Default TTL in seconds (default: 1 hour)
URL_FETCH_CACHE_TTL=3600

# Respect server Cache-Control headers (default: true)
URL_FETCH_CACHE_RESPECT_CACHE_CONTROL=true
```

#### ⚠️ Generic Cache System Settings (NOT for URL Fetch Cache)

**Important:** TimeTiles has a separate generic cache system used by other components. The variables below do **NOT** affect the URL fetch cache. Only use the `URL_FETCH_CACHE_*` variables above.

```bash
# ❌ These settings do NOT affect URL fetch cache ❌

CACHE_BACKEND=filesystem        # URL fetch cache ignores this
CACHE_DIR=.cache                # URL fetch cache ignores this
CACHE_DEFAULT_TTL=3600          # URL fetch cache ignores this
CACHE_MAX_ENTRIES=1000          # URL fetch cache ignores this
CACHE_MAX_SIZE_MB=500           # URL fetch cache ignores this
CACHE_CLEANUP_INTERVAL_MS=3600000  # URL fetch cache ignores this
```

**Why the separation?**

The URL fetch cache is a standalone system specifically designed for scheduled URL imports with HTTP-specific features (ETags, 304 responses, Cache-Control headers). It doesn't use `CacheManager` and has its own dedicated configuration.

**What you need to know:**
- Setting `CACHE_BACKEND=memory` will NOT make URL fetch cache use memory storage
- URL fetch cache always uses filesystem at `URL_FETCH_CACHE_DIR` location
- Only `URL_FETCH_CACHE_*` variables control URL fetch caching behavior

### Scheduled Import Settings

Configure caching behavior per scheduled import in the Payload admin:

**`advancedOptions.useHttpCache`**
- **Type:** Boolean
- **Default:** `true`
- **Description:** Enable HTTP caching for this import
- **Use case:** Disable for real-time data sources that change frequently

**`advancedOptions.bypassCacheOnManual`**
- **Type:** Boolean
- **Default:** `false`
- **Description:** Skip cache when manually triggering this import
- **Use case:** Force fresh data fetch during testing or debugging

**`advancedOptions.respectCacheControl`**
- **Type:** Boolean
- **Default:** `true`
- **Description:** Honor server `Cache-Control` headers
- **Use case:** Disable to override server caching directives with `URL_FETCH_CACHE_TTL`

### Storage Backend

The URL fetch cache uses **file system storage only** (persistent disk-based caching):

**Characteristics:**
- Persistent across server restarts and deployments
- Configurable size limits and TTL
- Expired entries removed on next access (lazy cleanup)
- Hierarchical file organization

**Configuration:**
```bash
URL_FETCH_CACHE_DIR=/tmp/url-fetch-cache  # Cache directory (default)
URL_FETCH_CACHE_MAX_SIZE=104857600   # Max size in bytes (default 100MB)
```

**Storage structure:**
```
/tmp/url-fetch-cache/
├── index.json          # Cache metadata and key index
└── entries/
    ├── abc123.cache    # Individual cache entries
    └── def456.cache
```

**Automatic Cleanup:**

The URL fetch cache has automatic cleanup enabled via a scheduled Payload job that runs every 6 hours. This job removes expired cache entries based on their TTL, preventing unbounded growth. Manual cleanup is rarely needed unless you want to force cache clearing.

**Note:** While TimeTiles has a generic cache system that supports configurable backends (`CACHE_BACKEND`), the URL fetch cache does not use that system and is hardcoded to use filesystem storage for persistence and reliability.

## How It Works

### Cache Key Generation

Cache keys are generated from:

1. **URL** - Normalized for consistent caching
2. **HTTP Method** - GET, POST, etc.

**URL Normalization:**

URLs are automatically normalized to maximize cache hits:

1. **Hostname lowercased** - `API.Example.com` → `api.example.com`
2. **Default ports removed** - `:80` (HTTP) and `:443` (HTTPS) are stripped
3. **Trailing slashes removed** - `https://api.example.com/data/` → `https://api.example.com/data`
4. **Query parameters sorted** - `?b=2&a=1` → `?a=1&b=2`
5. **Fragments removed** - `#section` is stripped

**Example:**
```
Original: https://API.Example.com:443/events/?limit=100&format=json#top
Method:   GET
→ Normalized: https://api.example.com/events?format=json&limit=100
→ Key:        GET:https://api.example.com/events?format=json&limit=100
```

**These URLs now cache as the same entry:**
- `https://api.example.com/data`
- `https://API.Example.com/data/`
- `https://api.example.com:443/data`
- `https://api.example.com/data?b=2&a=1` and `https://api.example.com/data?a=1&b=2`

### HTTP Caching Standards

The cache implements RFC 7234 (HTTP Caching) standards:

#### ETag (Entity Tag)

Server provides a unique identifier for the response version:

```http
Response Headers:
  ETag: "abc123xyz"
```

On next request, cache sends:
```http
Request Headers:
  If-None-Match: "abc123xyz"
```

If unchanged, server responds `304 Not Modified` (no body, minimal bandwidth).

#### Last-Modified

Server indicates when resource was last updated:

```http
Response Headers:
  Last-Modified: Wed, 21 Oct 2025 07:28:00 GMT
```

On next request, cache sends:
```http
Request Headers:
  If-Modified-Since: Wed, 21 Oct 2025 07:28:00 GMT
```

If unchanged, server responds `304 Not Modified`.

#### Cache-Control

Server specifies caching directives:

**`max-age=N`** - Cache for N seconds
```http
Cache-Control: max-age=3600  # Cache for 1 hour
```

**`no-cache`** - Revalidate before using cached response
```http
Cache-Control: no-cache  # Always check with server
```

**`no-store`** - Never cache
```http
Cache-Control: no-store  # Don't cache at all
```

**`private`** - Do not cache (intended for browser-only caching)

### TTL Calculation Logic

The cache determines Time-To-Live (TTL) using this priority order:

1. **`Cache-Control: no-store`** → Don't cache (TTL = 0)
2. **`Cache-Control: no-cache`** → Don't cache (TTL = 0)
3. **`Cache-Control: max-age=N`** → Use N seconds
4. **`Expires` header** → Calculate from expiration date
5. **Default TTL** → Use `URL_FETCH_CACHE_TTL` environment variable

**Example:**
```typescript
// Server response
Cache-Control: max-age=7200

// Cache stores entry with TTL = 7200 seconds (2 hours)
// After 2 hours, entry is stale and will be revalidated or evicted
```

### Cache Headers

The URL fetch cache adds a custom header to responses for debugging:

**`X-Cache`** - Cache status
- `HIT` - Served from cache
- `MISS` - Fetched from origin server
- `STALE` - Cached but expired, fallback used after revalidation failure
- `REVALIDATED` - 304 response received, cache metadata updated

**Example response:**
```http
HTTP/1.1 200 OK
X-Cache: HIT
Content-Type: application/json

{ ... }
```

## Monitoring & Management

### Cache Directory Inspection

Inspect cache contents directly via filesystem:

```bash
# List cached entries
ls -lh /tmp/url-fetch-cache/*/

# View cache index
cat /tmp/url-fetch-cache/index.json | jq .

# Check total cache size
du -sh /tmp/url-fetch-cache/

# Count entries
find /tmp/url-fetch-cache -name "*.cache" | wc -l
```

### Manual Cache Operations

#### Clear All URL Fetch Cache Entries

```bash
# Remove all cache entries
rm -rf /tmp/url-fetch-cache/*
```

**Note:** The cache will automatically rebuild as new requests are made.

## Troubleshooting

### Cache Misses Are Too High

**Symptoms:** Hit rate below 50%, frequent re-fetching of same URLs

**Possible Causes:**

1. **TTL too short** - Entries expire before next fetch
   ```bash
   # Increase default TTL to 24 hours
   URL_FETCH_CACHE_TTL=86400
   ```

2. **Server sends `Cache-Control: no-cache`** - Server prevents caching
   ```bash
   # Override server directives (use with caution)
   URL_FETCH_CACHE_RESPECT_CACHE_CONTROL=false
   ```

3. **Dynamic URLs** - Query parameters change each request
   - Check that URLs are consistent (same param order, values)
   - Normalize URLs in scheduled import configuration

4. **Cache eviction** - Cache size limit reached
   ```bash
   # Increase cache size to 500MB
   URL_FETCH_CACHE_MAX_SIZE=524288000
   ```

### Stale Data Returned

**Symptoms:** Cache returns old data when source has updated

**Possible Causes:**

1. **Server doesn't provide ETag or Last-Modified** - No revalidation possible
   - Check response headers from origin server
   - Contact API provider to enable conditional request support

2. **Revalidation failing** - 304 responses not working correctly
   - Check logs for `X-Cache: REVALIDATED` header
   - Verify server properly handles `If-None-Match` and `If-Modified-Since`

3. **TTL too long** - Data outdated before cache expires
   ```bash
   # Reduce TTL to 30 minutes
   URL_FETCH_CACHE_TTL=1800
   ```

**Solutions:**

```bash
# Force cache bypass for manual triggers
# In scheduled import config:
advancedOptions.bypassCacheOnManual = true

# Clear all URL fetch cache
rm -rf /tmp/url-fetch-cache/*
```

### Disk Space Issues

**Symptoms:** Cache directory growing too large, disk space warnings

**Diagnosis:**
```bash
# Check cache size
du -sh /tmp/url-fetch-cache/

# Count entries
find /tmp/url-fetch-cache -name "*.cache" | wc -l
```

**Solutions:**

1. **Reduce max cache size**
   ```bash
   URL_FETCH_CACHE_MAX_SIZE=52428800  # 50MB
   ```

2. **Reduce TTL** - Entries expire faster
   ```bash
   URL_FETCH_CACHE_TTL=1800  # 30 minutes
   ```

3. **Manual cleanup**
   ```bash
   # Clear all cache entries
   rm -rf /tmp/url-fetch-cache/*
   ```

### Debug Cache Behavior

**Enable detailed logging:**

Check application logs for cache operations:

```
[INFO] URL fetch cache HIT for https://api.example.com/data
[INFO] URL fetch cache MISS for https://api.example.com/live
[INFO] URL fetch cache REVALIDATED (304) for https://api.example.com/data
```

**Check response headers:**

```bash
# Fetch via import and inspect logs for X-Cache header
# Look for:
X-Cache: HIT          # Served from cache
X-Cache: MISS         # Fetched from origin
X-Cache: REVALIDATED  # 304 response, cache updated
```

**Inspect cache directory:**

```bash
# Check cache size and entry count
du -sh /tmp/url-fetch-cache/
find /tmp/url-fetch-cache -name "*.cache" | wc -l
```

**Common debug scenarios:**

1. **"Why isn't this URL being cached?"**
   - Check response for `Cache-Control: no-store` or `no-cache`
   - Verify `useHttpCache: true` in scheduled import settings
   - Check logs for "TTL=0" indicating non-cacheable response

2. **"Cache hit but data seems fresh, not stale"**
   - Server properly handling 304 revalidation
   - Check for ETag or Last-Modified in response headers
   - This is GOOD - cache working as intended

3. **"Same URL, different responses each time"**
   - URL may include timestamp or random parameter
   - Normalize URL to remove variable parameters
   - Consider if caching is appropriate for this endpoint

## Best Practices

### When to Enable Caching

**Good candidates:**
- ✅ Reference data that changes infrequently (country codes, categories)
- ✅ Historical data that never changes (past event records)
- ✅ Data with proper ETags or Last-Modified headers
- ✅ APIs with strict rate limits
- ✅ Large datasets (reduces bandwidth and processing time)

**Poor candidates:**
- ❌ Real-time data (stock prices, live scores)
- ❌ User-specific data with authentication tokens
- ❌ APIs that explicitly disable caching (`Cache-Control: no-store`)
- ❌ Data that must always be fresh (breaking news, alerts)

### Production Configuration

**Recommended settings for production:**

```bash
# URL fetch cache directory (use persistent location)
URL_FETCH_CACHE_DIR=/var/cache/timetiles/http

# Reasonable defaults for most use cases
URL_FETCH_CACHE_MAX_SIZE=524288000    # 500MB
URL_FETCH_CACHE_TTL=3600              # 1 hour
URL_FETCH_CACHE_RESPECT_CACHE_CONTROL=true
```

### Development Configuration

**Recommended settings for development:**

```bash
# Use shorter TTL for testing
URL_FETCH_CACHE_DIR=.cache/http
URL_FETCH_CACHE_MAX_SIZE=52428800     # 50MB
URL_FETCH_CACHE_TTL=300               # 5 minutes (shorter for testing)
```

### Testing Configuration

URL fetch cache is used in tests when testing scheduled imports. The cache directory is typically set to a temporary location. Test isolation is handled by the test framework.

## Implementation Details

For developers working on the cache system itself:

**Source Code:**
- `lib/services/cache/` - Generic cache system
  - `cache.ts` - Core cache service with key prefixing
  - `manager.ts` - Cache instance factory and lifecycle
  - `url-fetch-cache.ts` - HTTP-specific caching logic ⚠️
  - `storage/` - Storage backend implementations
- `lib/jobs/handlers/url-fetch-job/` - Integration with scheduled imports
  - `fetch-utils.ts` - HTTP fetch with cache support

**Architecture Note:**

⚠️ **Known quirk:** The URL fetch cache doesn't use `CacheManager` - it's a standalone singleton that directly instantiates its own storage backend. This means:

- `UrlFetchCache` constructor reads `URL_FETCH_CACHE_*` env vars directly
- Generic cache settings (`CACHE_BACKEND`, etc.) don't apply
- URL fetch cache is not registered with `CacheManager.instances`

**Potential improvement:** Refactor to use `CacheManager.getCache("http")` and respect generic cache settings where appropriate, while maintaining HTTP-specific features (ETags, Cache-Control).

**Auto-Generated API Documentation:**
- See `/reference/api/lib/services/cache/` for complete API reference
- TypeDoc comments in source code provide detailed documentation

**Related Systems:**
- [Data Processing Pipeline](/developer-guide/architecture/data-processing-pipeline) - How imports flow through the system
- [Scheduled Imports](/reference/api/lib/collections/scheduled-imports) - Configuration and fields
- [Quota System](/developer-guide/quotas) - How caching affects quota usage
