---
title: "Import System Development Guide"
description: "A comprehensive guide for developers working on the event data import system."
---

# Import System Development Guide

A comprehensive guide for developers working on the event data import system.

## Development Setup

### Prerequisites

- Node.js 18+ and pnpm
- PostgreSQL 17 with PostGIS extension
- Docker and Docker Compose (recommended)

### Environment Configuration

1. **Copy environment file**:

   ```bash
   cp apps/web/.env.example apps/web/.env.local
   ```

2. **Configure required variables**:

   ```bash
   # Database (automatically configured with Docker)
   DATABASE_URL=postgresql://timetiles_user:timetiles_password@localhost:5432/timetiles

   # Payload CMS
   PAYLOAD_SECRET=your-secret-key-here
   NEXT_PUBLIC_PAYLOAD_URL=http://localhost:3000

   # Geocoding (optional but recommended)
   GOOGLE_MAPS_API_KEY=your_google_maps_api_key_here
   ```

3. **Start development environment**:
   ```bash
   # From project root
   make setup  # Install dependencies and setup
   make dev    # Start infrastructure and development server
   ```

### Google Maps API Setup

For full geocoding functionality:

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select existing one
3. Enable the **Geocoding API**
4. Create credentials (API Key)
5. Restrict the API key to Geocoding API for security
6. Add the key to your `.env.local` file

**Note**: The system will fall back to OpenStreetMap Nominatim if Google Maps API is not configured.

## Architecture Overview

### System Components

```mermaid
graph TD
    A[File Upload] --> B[Import Record Creation]
    B --> C[File Parsing Job]
    C --> D[Batch Processing Jobs]
    D --> E[Event Creation Jobs]
    E --> F[Geocoding Batch Jobs]
    F --> G[Completion]

    H[Progress API] --> I[Real-time Updates]
    J[Rate Limiting] --> A
    K[Geocoding Cache] --> F
```

### Core Services

#### 1. GeocodingService (`lib/services/geocoding/GeocodingService.ts`)

Handles address geocoding with multiple providers and caching:

```typescript
import { GeocodingService } from "../lib/services/geocoding/GeocodingService";

const geocodingService = new GeocodingService(payload);

// Single address geocoding
const result = await geocodingService.geocode("123 Main St, San Francisco, CA");

// Batch geocoding
const results = await geocodingService.batchGeocode(
  ["123 Main St, San Francisco, CA", "456 Oak Ave, New York, NY"],
  10,
); // batch size
```

**Key Features**:

- Provider fallback (Google Maps → Nominatim)
- Intelligent caching with hit counting
- Confidence scoring
- Rate limiting between batches
- Automatic cache cleanup

#### 2. RateLimitService (`lib/services/RateLimitService.ts`)

Manages rate limiting for unauthenticated users:

```typescript
import {
  getRateLimitService,
  RATE_LIMITS,
} from "../lib/services/RateLimitService";

const rateLimitService = getRateLimitService(payload);

// Check rate limit
const result = await rateLimitService.checkRateLimit(
  clientId,
  RATE_LIMITS.FILE_UPLOAD.limit,
  RATE_LIMITS.FILE_UPLOAD.windowMs,
);

if (!result.allowed) {
  // Handle rate limit exceeded
  console.log(`Rate limited. Reset at: ${new Date(result.resetTime)}`);
}
```

**Key Features**:

- In-memory rate limiting with configurable windows
- Per-endpoint rate limits
- Automatic cleanup of expired entries
- HTTP header integration
- Client identification (IP-based)

### Job System Architecture

The import system uses Payload's built-in job queue for background processing:

#### Job Flow

1. **File Parsing Job** (`file-parsing`)

   - Parses CSV/Excel files
   - Validates required fields
   - Calculates total row count
   - Queues batch processing jobs

2. **Batch Processing Job** (`batch-processing`)

   - Processes data in configurable batches
   - Normalizes and validates data
   - Queues event creation jobs

3. **Event Creation Job** (`event-creation`)

   - Creates event records in database
   - Handles validation errors gracefully
   - Queues geocoding jobs for events with addresses

4. **Geocoding Batch Job** (`geocoding-batch`)
   - Geocodes event addresses in batches
   - Updates events with coordinates and metadata
   - Handles provider fallbacks and caching

#### Job Configuration

Jobs are defined in `lib/jobs/import-jobs.ts`:

```typescript
export const fileParsingJob: JobConfig = {
  slug: "file-parsing",
  handler: async ({ job, payload }) => {
    // Job implementation
  },
};
```

### Database Schema

#### Collections

1. **Imports Collection** (`lib/collections/Imports.ts`)

   - Tracks import jobs with comprehensive metadata
   - Progress tracking and batch information
   - Geocoding statistics and error tracking

2. **Events Collection** (`lib/collections/Events.ts`)

   - Stores imported events with geocoding metadata
   - Location data and import tracking

3. **LocationCache Collection** (`lib/collections/LocationCache.ts`)
   - Caches geocoding results for efficiency
   - Provider information and confidence scores

#### Key Fields

**Import Record**:

```typescript
{
  fileName: string;
  originalName: string;
  catalog: Relationship;
  status: "pending" | "processing" | "completed" | "failed";
  processingStage: string;
  progress: {
    totalRows: number;
    processedRows: number;
    geocodedRows: number;
    createdEvents: number;
    percentage: number;
  }
  batchInfo: {
    batchSize: number;
    currentBatch: number;
    totalBatches: number;
  }
  geocodingStats: {
    totalAddresses: number;
    successfulGeocodes: number;
    failedGeocodes: number;
    cachedResults: number;
    googleApiCalls: number;
    nominatimApiCalls: number;
  }
}
```

## Running Tests

### Test Structure

The import system has comprehensive test coverage:

```
apps/web/__tests__/
├── file-parsing.test.ts          # File parsing logic
├── geocoding-service.test.ts     # Geocoding service
├── rate-limit-service.test.ts    # Rate limiting
├── import-jobs.test.ts           # Job handlers
├── import-api.test.ts            # API endpoints
└── import-integration.test.ts    # Full workflow tests
```

### Running Tests

```bash
# Run all tests
pnpm test

# Run specific test file
pnpm test import-integration.test.ts

# Run tests in watch mode
pnpm test --watch

# Run tests with coverage
pnpm test --coverage
```

### Test Database Setup

Tests use a separate test database:

```bash
# Set test database URL in .env.local
DATABASE_URL_TEST=postgresql://timetiles_user:timetiles_password@localhost:5432/timetiles_test

# Tests automatically handle database setup and cleanup
```

### Writing Tests

Example test structure:

```typescript
import { createSeedManager } from "../lib/seed/index";

describe("Import Feature Tests", () => {
  let seedManager: any;
  let payload: any;

  beforeAll(async () => {
    seedManager = createSeedManager();
    await seedManager.initialize();
    payload = seedManager.payload;
  });

  afterAll(async () => {
    await seedManager.cleanup();
  });

  beforeEach(async () => {
    // Clear collections
    await payload.delete({ collection: "imports", where: {} });
    await payload.delete({ collection: "events", where: {} });
  });

  it("should process import successfully", async () => {
    // Test implementation
  });
});
```

### Mock Data and Fixtures

Use the sample data for testing:

```typescript
// Sample CSV data
const sampleData = [
  {
    title: "Tech Conference 2024",
    description: "Annual technology conference",
    date: "2024-03-15",
    address: "123 Main St, San Francisco, CA",
  },
];

// Mock file upload
const file = new File([csvContent], "test-events.csv", {
  type: "text/csv",
});
```

## Performance Optimization

### Batch Processing Configuration

Optimize batch sizes based on your system:

```bash
# Environment variables
BATCH_SIZE=100                    # Rows per batch (default: 100)
GEOCODING_BATCH_SIZE=10          # Addresses per geocoding batch
GEOCODING_DELAY_MS=1000          # Delay between geocoding batches
```

**Recommendations**:

- **Small systems**: Batch size 50-100
- **Medium systems**: Batch size 100-200
- **Large systems**: Batch size 200-500
- **Geocoding**: Keep batch size low (5-20) to respect API limits

### Database Optimization

#### Indexes

Key indexes for performance:

```sql
-- Import progress queries
CREATE INDEX idx_imports_status ON imports(status);
CREATE INDEX idx_imports_stage ON imports(processing_stage);

-- Event queries
CREATE INDEX idx_events_import_id ON events(import_id);
CREATE INDEX idx_events_geocoding ON events((geocoding->>'needsGeocoding'));

-- Location cache
CREATE INDEX idx_location_cache_address ON location_cache(normalized_address);
CREATE INDEX idx_location_cache_cleanup ON location_cache(hit_count, last_used);
```

#### Query Optimization

```typescript
// Efficient progress queries
const importRecord = await payload.findByID({
  collection: "imports",
  id: importId,
  select: {
    status: true,
    processingStage: true,
    progress: true,
    batchInfo: true,
    geocodingStats: true,
  },
});

// Batch event creation
const events = await payload.create({
  collection: "events",
  data: eventDataArray, // Batch insert
});
```

### Memory Management

#### Large File Handling

```typescript
// Stream processing for large files
import { createReadStream } from "fs";
import { pipeline } from "stream/promises";

async function processLargeFile(filePath: string) {
  const readStream = createReadStream(filePath);
  const parseStream = Papa.parse(Papa.NODE_STREAM_INPUT, {
    header: true,
    step: (results) => {
      // Process row by row
      processRow(results.data);
    },
  });

  await pipeline(readStream, parseStream);
}
```

#### Garbage Collection

```typescript
// Clean up after processing
try {
  // Process file
  await processImport(importId);
} finally {
  // Clean up uploaded file
  if (fs.existsSync(filePath)) {
    fs.unlinkSync(filePath);
  }

  // Force garbage collection in development
  if (global.gc && process.env.NODE_ENV === "development") {
    global.gc();
  }
}
```

## Debugging and Monitoring

### Logging Configuration

Enhanced logging for development:

```typescript
// In job handlers
console.log(`[${job.task}] Processing import ${importId}`);
console.log(`[${job.task}] Batch ${batchNumber}/${totalBatches}`);
console.error(`[${job.task}] Error:`, error);

// Structured logging (recommended)
const logger = {
  info: (message: string, meta?: any) => {
    console.log(
      JSON.stringify({
        level: "info",
        message,
        timestamp: new Date().toISOString(),
        ...meta,
      }),
    );
  },
  error: (message: string, error?: Error, meta?: any) => {
    console.error(
      JSON.stringify({
        level: "error",
        message,
        error: error?.message,
        stack: error?.stack,
        timestamp: new Date().toISOString(),
        ...meta,
      }),
    );
  },
};
```

### Debug Endpoints

Add debug endpoints for development:

```typescript
// apps/web/app/api/debug/import/[importId]/route.ts
export async function GET(
  request: NextRequest,
  { params }: { params: { importId: string } },
) {
  if (process.env.NODE_ENV !== "development") {
    return NextResponse.json(
      { error: "Not available in production" },
      { status: 404 },
    );
  }

  const payload = await getPayload({ config });

  // Get detailed import information
  const importRecord = await payload.findByID({
    collection: "imports",
    id: params.importId,
  });

  // Get related events
  const events = await payload.find({
    collection: "events",
    where: { importId: { equals: params.importId } },
    limit: 10,
  });

  return NextResponse.json({
    import: importRecord,
    events: events.docs,
    debug: {
      timestamp: new Date().toISOString(),
      nodeEnv: process.env.NODE_ENV,
      memoryUsage: process.memoryUsage(),
    },
  });
}
```

### Performance Profiling

```typescript
// Measure job performance
async function profiledJobHandler({ job, payload }) {
  const startTime = Date.now();
  const startMemory = process.memoryUsage();

  try {
    await originalJobHandler({ job, payload });
  } finally {
    const endTime = Date.now();
    const endMemory = process.memoryUsage();

    console.log(`Job ${job.task} completed in ${endTime - startTime}ms`);
    console.log(
      `Memory delta: ${(endMemory.heapUsed - startMemory.heapUsed) / 1024 / 1024}MB`,
    );
  }
}
```

### Queue Monitoring

Monitor job queue status:

```typescript
// Get queue statistics
async function getQueueStats(payload: Payload) {
  const jobs = await payload.find({
    collection: "payload-jobs",
    where: {
      task: {
        in: [
          "file-parsing",
          "batch-processing",
          "event-creation",
          "geocoding-batch",
        ],
      },
    },
    sort: "-createdAt",
    limit: 100,
  });

  const stats = jobs.docs.reduce((acc, job) => {
    acc[job.task] = acc[job.task] || {
      total: 0,
      completed: 0,
      failed: 0,
      running: 0,
    };
    acc[job.task].total++;
    acc[job.task][job.status]++;
    return acc;
  }, {});

  return stats;
}
```

## Contributing Guidelines

### Code Style

The project uses ESLint and Prettier:

```bash
# Check code style
pnpm lint

# Fix code style issues
pnpm lint --fix

# Format code
pnpm format
```

### Pull Request Process

1. **Create feature branch**:

   ```bash
   git checkout -b feature/import-enhancement
   ```

2. **Make changes with tests**:

   - Add/update functionality
   - Write comprehensive tests
   - Update documentation

3. **Run quality checks**:

   ```bash
   pnpm lint
   pnpm test
   pnpm build
   ```

4. **Submit pull request**:
   - Clear description of changes
   - Link to related issues
   - Include test results

### Testing Requirements

All new features must include:

- **Unit tests** for individual functions/classes
- **Integration tests** for API endpoints
- **End-to-end tests** for complete workflows
- **Performance tests** for large data scenarios

### Documentation Updates

When adding features:

1. Update relevant documentation files
2. Add API examples if applicable
3. Update environment variable documentation
4. Include troubleshooting information

## Common Development Scenarios

### Adding a New File Format

1. **Update file validation**:

   ```typescript
   // In upload route
   const ALLOWED_MIME_TYPES = [
     "text/csv",
     "application/vnd.ms-excel",
     "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
     "application/json", // New format
   ];
   ```

2. **Add parsing logic**:

   ```typescript
   // In file parsing job
   if (fileType === "json") {
     const fileContent = fs.readFileSync(filePath, "utf8");
     parsedData = JSON.parse(fileContent);
   }
   ```

3. **Update tests and documentation**

### Adding New Geocoding Provider

1. **Extend GeocodingService**:

   ```typescript
   // Add new provider
   if (this.customGeocoder) {
     providers.push({ name: "custom", geocoder: this.customGeocoder });
   }
   ```

2. **Update configuration**:

   ```bash
   # Add environment variable
   CUSTOM_GEOCODING_API_KEY=your_key_here
   ```

3. **Add provider-specific confidence calculation**

### Customizing Batch Processing

1. **Environment configuration**:

   ```bash
   BATCH_SIZE=200
   GEOCODING_BATCH_SIZE=20
   ```

2. **Dynamic batch sizing**:
   ```typescript
   const batchSize = Math.min(
     parseInt(process.env.BATCH_SIZE || "100"),
     Math.ceil(totalRows / 10), // Adaptive sizing
   );
   ```

## Troubleshooting Development Issues

### Common Problems

1. **Jobs not processing**:

   - Check Payload job queue configuration
   - Verify database connectivity
   - Review job handler errors

2. **Geocoding failures**:

   - Verify API key configuration
   - Check API quotas and billing
   - Test with sample addresses

3. **Memory issues with large files**:

   - Reduce batch size
   - Implement streaming processing
   - Monitor memory usage

4. **Test failures**:
   - Ensure test database is clean
   - Check mock configurations
   - Verify async/await usage

### Debug Commands

```bash
# Check database connection
pnpm exec payload migrate:status

# Reset development database
make db-reset

# View container logs
make logs

# Check job queue
curl http://localhost:3000/api/debug/jobs
```

---

For more information, see:

- [Import System Overview](../features/import-system)
- [API Documentation](../api/import)
- [Troubleshooting Guide](../guides/troubleshooting)
